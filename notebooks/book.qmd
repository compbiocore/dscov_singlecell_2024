---
title: "DSCoV Single Cell"
editor: visual
format: 
  html:
    page-layout: article
---

```{r}
#| echo: false
library(knitr)
opts_chunk$set(fig.align='center', fig.width=7, fig.height=5, 
cache=TRUE, size="small")
```

# scRNAseq analysis with Seurat
## To use this notebook

1.  Go to `ood.ccv.brown.edu` (you will need an Oscar account).
2.  Go to `Clusters` in the blue menu bar at the top and click the drop-down that says '\>\_OSCAR Shell Access'
3.  Go to your home folder (`cd ~`)
4.  Git clone the repo (`git clone https://github.com/compbiocore/dscov_singlecell_2024.git`).
5.  Go back to `ood.ccv.brown.edu` and look under `Interactive Apps` in the blue menu bar and click on `RStudio on Singularity` under `Expert GUIs`.

Fill in the fields as follows:

-   `Account`: leave blank\
-   `Partition`: leave blank\
-   `Number of hours`: 3\
-   `Num Cores`: 8\
-   `Memory`: 90\
-   `Singularity Container Path`: /oscar/data/shared/databases/workshops/dscov/dscov_singlecell_2024/metadata/dscov_singlecell_2024:latest.sif\
-   `Package install Path`: leave blank\
-   `Path for R Executable`: This should be the full path to where you cloned the repo in step 4.\
-   `R Module`: leave blank\
-   `Additional Data Path`: leave blank\

Once your job starts, click the button to connect to session.\
At the top of the screen you'll see a menu bar that starts with 'file', click on 'file' and 'open file'.\
Open the `dscov_singlecell_2024.Rproj` file in the root folder of the repo.\

## Introduction to scRNA-seq

Much of this notebook is adapted from the Seurat vignettes https://satijalab.org/seurat and GitHub repository https://github.com/satijalab/seurat

How does scRNAseq differ from bulk RNA-seq? In bulk RNA-seq you are taking a snapshot of expression of all the cells in a sample and your measurements are aggregated across all of those cells. In scRNAseq, you can get a sense of the heterogeneity of the cells in your sample. Are there novel or rare cell types? What about cell type specific gene expression? Does the distribution of different cell types change across time or treatment? This increased resolution comes with some unique challenges: 

* Dropouts - genes that are not detected in some cells, can lead to sparse expression matrices with many zero values.

* Doublets - sequencing two cells at the same time and can't distinguish their expression or cell types, need to filter these out during QC.

* Dying cells - you will lose some cells because they are dead or dying, you can also filter these out during sample QC.

* You also should be cautious when thinking about your sample sizes. For example, you may be sequencing thousands of cells but if they all come from the same mouse you lose the ability to generalize your findings.
   

## Seurat objects overview

::: callout-important
In November of 2023, Seurat made a major upgrade to Seurat v5 (https://github.com/satijalab/seurat/releases), which included many new functions and other changes (https://satijalab.org/seurat/articles/announcements.html#changes-in-seurat-v5), including some very big changes to the default behavior of Seurat. **You will likely see different results depending on which version of Seurat you have used for your analysis.** Feel free to come to our office hours if you want help setting up reproducible analyses using either version of Seurat.
:::

This workshop focuses on using Seurat objects to structure your scRNA-seq data (https://github.com/satijalab/seurat/wiki/Seurat), we will attempt to cover how to interact with Seurat objects in Seurat v4 and v5, but won't exhaustively cover the differences between the two versions.

Here's a schematic of a Seurat object:

![Schematic of a Seurat object](image/seurat_object.png){width="470" height="400"}

-   Each Seurat object is composed of different components:
    -   **`assays`** is a list of all the assays in the object.
        -   Defaults to `RNA` assay, but you can add others (like `SCT` for normalizd counts, shown in the figure above, could also be antibody-derived tags, etc.).

        -   You can see all assays using `Assays(ifnb)`, see which assay is the currently active assay by looking in the `active.assay` slot (`ifnb@active.assay`) and switch between them using the `DefaultAssay()` function (`DefaultAssay(ifnb) <- 'RNA'`).

        -   Each assay will store multiple transformations of the data in different `slots` (or `layers` in Seurat v5) -- in the case of `RNA` data these slots are:

            -   `@counts` contains the raw counts.
            -   `@data` contains the normalized counts.
            -   `@scale.data` contains the scaled data for dimensional reduction.

        -   The `slots` (Seurat v4) or `layers` (Seurat v5) store the data as a sparse matrix where the rows are gene and the columns are cells.

        -   In Seurat v4, you could access the raw counts like this:`GetAssayData(ifnb, assay="RNA", slot='counts')`. This will still work in Seurat v5, but you'll get a warning message. In Seurat v5 it is intended that you access the counts using the `LayerData` function, like this: `LayerData(ifnb, assay='RNA', layer='counts')`

        -   In either version of Seurat `ifnb[['RNA']]$counts` will also work.
    -   **`meta.data`** is a matrix of all the cell-level metadata.
        -   This will include information about which condition, timepoint, batch, etc. a for a given cell.
        -   It also includes metrics that will be relevant for QC, like `nCount_RNA` and `nFeature_RNA`
            -   `nCount_RNA` is the total number of molecules (UMIs) detected within a cell.
            -   `nFeature_RNA` is the total number of genes detected within a cell.
        -   Once you have completed clustering, you'll also see information about which cluster each cell has been assigned to.
        -   The different categories or columns in the `meta.data` are also called `Idents` in Seurat.
        -   You can see the current `Ident` in the `active.ident` slot (`ifnb@active.ident`) and switch between them using the `Idents()` function (this will probably be important for running differential expression testing).
        -   You can use `table(Idents(ifnb))` for a quick summary of the number of cells in each grouping.
    -   **`graphs`** is a list of the nearest neighbor graphs.
        -   The objects stored in `graphs` are cell x cell matrices containing the neighborhood overlap (Jaccard index) between every cell and its nearest neighbors.
    -   **`reductions`** is a list of `DimReduc` objects.
    -   **`version`** contains information about which version of Seurat was used to make the object.
    -   There are other optional slots, including **`tools`** and **`misc`** that can be populated by specific analysis tools (`tools`) or users can store their own additional information (`misc`).

## Parallelization options for Seurat and other packages

First, we can set the `.libPaths()`, which essentially tells R that it should look for packages inside these locations inside the Singularity container.

```{r "set lib paths"}
.libPaths(c('/usr/local/lib/R/site-library', '/usr/local/lib/R/library'))
```

All of the methods we are discussing here involve computationally heavy methods, and as such also take advantage of parallelization where they can. Often in their documentation you will find how to use multiple cores when calling a function, usually involving a provided a rgument or involving a package called `future`. For example, Seurat has a [vignette on parallelization](https://satijalab.org/seurat/archive/v4.3/future_vignette) with `future`. We will follow it here:

```{r}
library(future)
# check the current active plan
plan()
```

`plan()` says that we are currently set up to run code *sequentially* or non-parallelized. To see more information, run this code chunk:

```{r}
?future::plan
```

Now, we set workers=8 because we've requested 8 cores. Additionally, we set `multisession` instead of `multiprocess` despite what the vignette says, because `multiprocess` is actually deprecated in `future` and we should be explicitly specifying `multisession` or `multico re` instead. Getting into the difference is out of scope of this workshop, but you can [read more](https://cran.r-project.org/web/packages/future/vignettes/future-1-overview.html) on future yourself if interested.

```{r}
# change the current plan to access parallelization
plan("multisession", workers = 4)
plan()
```

We'll also set a seed at the start of the notebook so that we can reproduce our results if we decide to re-run this notebook at some future date. We also set `future.globals.maxSize`, see the Seurat future vignette linked above for discussion about why we do this (basical ly we might be exceeding the allowed global variable size so we make that default bigger). We will also track how long it takes us to run through this notebook:

```{r}
set.seed(61)
options(future.globals.maxSize = 4000 * 1024^2)
nb.start.time <- Sys.time()
```

## Importing data and interacting with Seurat objects

**Much of this notebook is taken from the various Seurat vignettes: https://satijalab.org/seurat/articles/get_started.html** First, load all the libraries we need, including some Seurat data packages. The last line will update the Seurat objects so that they are compatible with the newest version of Seurat.

```{r message=FALSE, warning=FALSE}
library(RColorBrewer)
library(Seurat)
library(patchwork)
library(ggplot2)
library(dplyr)
library(hdf5r)
library(stringr)
library(biomaRt)
library(viridis)
library(SeuratData)
library('ifnb.SeuratData')
data("ifnb")
ifnb <- UpdateSeuratObject(ifnb)
```

-   We are using the `SeuratData` package for some test data.
-   Use `AvailableData()` to see what datasets are available

```{r}
SeuratData::AvailableData() %>% data.frame() %>% head()
SeuratData::AvailableData() %>% data.frame() %>% dplyr::filter(Installed == 'TRUE')
```

-   We've already installed some test data in this container. You would usually be able to install more data sets using `InstallData` but won't have permissions to install in this container.
-   It is more likely that you are using Seurat with your own data -- you can use the functions `Read10X` or `Read10X_h5` to import data.
-   `Read10X_h5` works with H5 files -- "Hierarchical Data Format (HDF5 or H5). H5 is a binary format that can compress and access data much more efficiently than text formats such as MEX, which is especially useful when dealing with large datasets." https://support.10xge nomics.com/single-cell-gene-expression/software/pipelines/latest/advanced/h5_matrices.
-   You can also use `Read10X` and give a path to a folder that contains your matrix, features, and barcode tsv files.
-   After you have read in the 10X data, use it as the input to the `CreateSeuratObject` function.

The `ifnb` dataset is 14,000 IFNB-Stimulated and Control PBMCs (peripheral blood mononuclear cells).

```{r}
?ifnb
```

Currently it has a `RNA` assay:

```{r}
ifnb@assays
```

We can look in the `metadata` slot. Each row is a cell, and we can see which experimental group the samples came from (`orig.ident` and `stim` both tell you this information), that the cell types have already been annotated (`seurat_annotations`) and that for each cell we have information about the number of genes (`nFeature_RNA`) and molecules (`nCount_RNA`) detected.

```{r}
head(ifnb@meta.data)
```

We can look at the Seurat object we've loaded from SeuratData and see that Seurat v5 assays store data in layers. These layers can store raw, un-normalized counts (layer='counts'), normalized data (layer='data') or z-scored/variance-stabilized data (layer='scale.data').

```{r}
ifnb
```

We will aim to eventually integrate the different samples (`IMMUNE_CTRL` and `IMMUNE_STIM"` from `orig.ident`) together. In previous versions of Seurat, we would require the data to be represented as a list different different Seurat objects. When using Seurat v5 assays, we can instead keep all the data in one object, but simply split the layers.

```{r}
ifnb[["RNA"]] <- split(ifnb[["RNA"]], f = ifnb$orig.ident)
ifnb
```

After splitting, there are now 4 layers (a counts and data layer for each batch). Since the data is split into layers, normalization and variable feature identification is performed for each sample independently (a consensus set of variable features is automatically identified).

## Data QC

-   We care about the percentage of reads that map to the mitochondrial genome because high mitochondrial reads in a cell can indicate that the cells are low-quality or dying cells. The mitochondrial QC metrics are calcualted with the `PercentageFeatureSet()` function, which calculates the percentage of counts originating from a set of features. We use the set of all genes starting with MT- as a set of mitochondrial genes -- the format of the mt sequences will vary depending on which organism/genome is used...(might be 'mt-' for example). In this `ifnb` test dataset, there are no mitochondrial reads.

```{r "Figure out format of MT gene IDs"}
rownames(ifnb) %>% grep(pattern = '^mt-', ignore.case = TRUE, value = TRUE)
```

```{r "add mt percent data"}
ifnb[["percent.mt"]] <- PercentageFeatureSet(ifnb, pattern = "^MT-")
```

-   Before we plot, we can set the order of the object idents to whatever order we'd like:

```{r}
Idents(ifnb) <- 'orig.ident'
levels(ifnb) <- c("IMMUNE_CTRL", "IMMUNE_STIM")
```

-   We can also look at plots showing the distribution of the `percent.mt`, `nFeature_RNA` and `nCount_RNA`
-   `nFeature_RNA` is the number of genes
-   `nCount_RNA` is the number of UMIs (unique molecules -- like counts)

```{r}
VlnPlot(ifnb, features = "nFeature_RNA")

VlnPlot(ifnb, features = "nCount_RNA")

VlnPlot(ifnb, features="percent.mt")
```

```{r}
FeatureScatter(ifnb, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")

FeatureScatter(ifnb, feature1 = "nCount_RNA", feature2 = "percent.mt")

FeatureScatter(ifnb, feature1 = "nFeature_RNA", feature2 = "percent.mt")
```

-   You can also just use ggplot to make your own custom visualizations of the information in the metadata.
-   We make a separate matrix called `qc_data` and sorting it based on the `percent.mt` column.
-   Then we make our own ggplot and specify that the x and y axes should be `nCount_RNA` and `nFeature_RNA` and that the points should be colored based on `percent.mt`.
-   We use `scale_color_gradientn` to specify how the points should be colored, specifying that the limit should be between 0 and 10 and that we should `squish` anything that is out of bounds (effectively making our limits 0 and \>10).

```{r}
qc_data <- ifnb@meta.data[c('orig.ident','nCount_RNA','nFeature_RNA','percent.mt')] %>% arrange(percent.mt)
ggplot(qc_data, aes(x = nCount_RNA, y = nFeature_RNA, color = percent.mt)) + 
  geom_point() + 
  scale_color_gradientn(colors = rev(brewer.pal(5, "Spectral")), limits = c(0,10), oob = (scales::squish)) +
  facet_wrap(~orig.ident) + 
  theme_bw()
```

-   Low quality cells or empty droplets might have very few genes (`nFeatures`)
-   Dead or dying cells will also have high mitochondrial reads (`percent.mt`)
-   Doublets or multiplets will have high gene counts (`nFeatures`)
-   The total number of molecules (`nCount`) detected in a cell corresponds with the number of genes (`nFeatures`)
-   Most of the cells have less than 2000 genes and less than 7000 or so UMIs.
-   Very low mitochondrial counts from the `ifnb` data and the nFeature_RNA scatter plots look strange -- perhaps this dataset was pre-filtered before being packaged into SeuratData.
-   Our goal in QC filtering is to retain as much useful information as we can, while removing doublets, empty droplets, and dead cells.
-   We will pick some thresholds for filtering based off of what we see in our data, keeping in mind that if you are doing this with your own data, your plots and thresholds will probably look a bit different.

## Data Filtering

-   Let's filter our data using `subset`, we'll keep cells that have between 500 and 7000 nFeature_RNA (genes), greater than 1000 molecules, and less than 5% mitochondrial reads.

```{r}
ifnb_sub <- subset(ifnb, subset = nFeature_RNA > 500 & nFeature_RNA < 7000 & percent.mt < 5 & nCount_RNA > 1000)
```

Then I'll subset the object to make is easier to work with and confirm that we have similar number of cells from each experimental group:

```{r}
ifnb_sub<- subset(ifnb_sub, cells = sample(x = rownames(ifnb_sub@assays$RNA@cells@.Data), size = 5000) )
table(ifnb_sub@meta.data$orig.ident)
```

## Normalization

### Theory

scRNAseq data is normalized so that we can mitigate technical effects while preserving the biological signal in the data -- we should be able to find the biological signal in cells irrespective of how deeply we sequenced the cell. The theory behind SCTransform (https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1) is very similar to the generalized linear models (GLMs) used in bulk RNAseq analysis packages like DESeq2 and edgeR. In DESeq2 a negative binomial model is fitted to the counts and the mean and dispersion (roughly speaking how variable the observed count will be from the mean count) estimates from that model are used as the test statistics for comparison between groups. The same idea applies with SCTransform, with an additional aspect where SCTransform pools information across genes with similar abundances in order to address the higher sparsity of single cell data. We generally find that SCTransform does an excellent job alleviating variance in your data from sequencing depth alone.

### When should you not use SCTransform?

The paper states: `As our workflow leverages all genes (or a random sub-set) for the initial regularization, we make an implicit assumption that the majority of genes in the dataset do not exhibit significant biological variation...this assumption may be overly simplistic when performing scRNA-seq on a highly heterogeneous sample, we did not observe adverse affects when applying our model to human PBMC data, or any of the other datasets we examined.`

SCTransform might not work well if your data is highly heterogeneous and you expect that a high proportion of genes will exhibit significant biological variation across your samples. In this case, we would recommend the more standard workflow of `NormalizeData`, `FindVariableFeatures`, and `ScaleData`.

### SCTransform versions

Seurat v5 run SCTransform v2 (https://satijalab.org/seurat/archive/v4.3/sctransform_v2_vignette) by default, while Seurat v4 ran SCTransform v1 by default. SCTransform v2 "improves speed and memory consumption, the stability of parameter estimates, the identification of variable features, and the the ability to perform downstream differential expression analyses." This means you might get different results if you run Seurat v5 and re-normalize data that you have previously processed with Seurat v4. If you want to change from the default veresion of SCTransform, you can add the argument `vst.flavor = "v1"` (or `vst.flavor = "v2"`))

### Running SCTransform

We will normalize using SCTransform and you might get see a warning that says 'iteration limit reached' when you run the function. This warning can be ignored (https://github.com/satijalab/sctransform/issues/25) because the parameter estimation generating this warning is regularized later anyway. You can use the `vars.to.regress` argument to regress out nuisance variables (like cell cycle, batch effects, or `percent.mt`). By default SCTransform will only return data for variable genes in the scale data slot -- adding the `return.only.var.genes = FALSE` argument to the function call to should solve this issue (https://github.com/satijalab/seurat/issues/3553). We will also track how long it takes to run:

```{r "SCTransform"}
start.time <- Sys.time()
ifnb_sub <- SCTransform(ifnb_sub, vars.to.regress = "percent.mt", verbose = FALSE, return.only.var.genes = FALSE)
end.time <- Sys.time()
end.time - start.time

```

Run PCA and make an elbow plot

```{r}

ifnb_sub <- RunPCA(ifnb_sub)
ElbowPlot(ifnb_sub)
```

Based on this plot, we get diminishing information returned once we get above \~10 PCs. We will use this information when we run clustering.

## Integration

Seurat v5 enables streamlined integrative analysis using the IntegrateLayers function. The method currently supports five integration methods. Each of these methods performs integration in low-dimensional space, and returns a dimensional reduction (i.e. integrated.rpca) that aims to co-embed shared cell types across batches (samples):

```         
Anchor-based CCA integration (method=CCAIntegration)
Anchor-based RPCA integration (method=RPCAIntegration)
Harmony (method=HarmonyIntegration)
FastMNN (method= FastMNNIntegration)
scVI (method=scVIIntegration)
```

A detailed discussion of these different methods is outside the scope of this workshop, but you can find more detail on each method in Seurat’s documentation. However, the Seurat authors state:

By identifying shared sources of variation between datasets, CCA is well-suited for identifying anchors when cell types are conserved, but there are very substantial differences in gene expression across experiments. CCA-based integration therefore enables integrative analysis when experimental conditions or disease states introduce very strong expression shifts, or when integrating datasets across modalities and species. However, CCA-based integration may also lead to overcorrection, especially when a large proportion of cells are non-overlapping across datasets. RPCA-based integration runs significantly faster, and also represents a more conservative approach where cells in different biological states are less likely to ‘align’ after integration. We therefore recommend RPCA during integrative analysis where: 

*    A substantial fraction of cells in one dataset have no matching type in the other
*    Datasets originate from the same platform (i.e. multiple lanes of 10x genomics)
*    There are a large number of datasets or cells to integrate (see here for more tips on integrating large datasets)

We will run `CCAIntegration` (this was the default flavor of integration in previous versions of Seurat), `RPCAIntegration`, and `HarmonyIntegration`. Note that we are specifying that we used `SCT` normalization:

```{r}
ifnb_sub <- IntegrateLayers(
  object = ifnb_sub, method = CCAIntegration,
  orig.reduction = "pca", new.reduction = "integrated.cca", normalization.method = "SCT",
  verbose = FALSE
)
```

```{r}
ifnb_sub <- IntegrateLayers(
  object = ifnb_sub, method = RPCAIntegration,
  orig.reduction = "pca", new.reduction = "integrated.rpca", normalization.method = "SCT",
  verbose = FALSE
)
```

```{r}
ifnb_sub <- IntegrateLayers(
  object = ifnb_sub, method = HarmonyIntegration,
  orig.reduction = "pca", new.reduction = "harmony", normalization.method = "SCT",
  verbose = FALSE
)
```

Seurat will cluster your cells into groups of cells with similar expression patterns. The first step is `FindNeighbors`, which will construct a K-nearest neighbor (KNN) graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). To cluster the cells, we run `FindClusters` to apply the Louvain algorithm to iteratively group cells together, with the goal of optimizing the standard modularity function. `FindClusters` takes a `resolution` argument (defaults to a value of 0.8), which sets the granularity of the clustering, setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells but the resolution might increase for larger datasets. Use a value above 1 if you want a larger number of communities (clusters), and a value below 1 if you want a smaller number of communities.

```{r}
ifnb_sub <- FindNeighbors(ifnb_sub, reduction = "integrated.cca", dims = 1:10)
ifnb_sub <- FindClusters(ifnb_sub, resolution = .8, cluster.name = "cca_clusters")

ifnb_sub <- FindNeighbors(ifnb_sub, reduction = "integrated.rpca", dims = 1:10)
ifnb_sub <- FindClusters(ifnb_sub, resolution = .8, cluster.name = "rpca_clusters")

ifnb_sub <- FindNeighbors(ifnb_sub, reduction = "harmony", dims = 1:10)
ifnb_sub <- FindClusters(ifnb_sub, resolution = .8, cluster.name = "harmony_clusters")

```

Run UMAP (Uniform Manifold Approximation and Projection) dimensional reduction technique on the unintegrated data and the different integration methods:

```{r}
ifnb_sub <- RunUMAP(ifnb_sub, dims = 1:10, reduction = "pca", reduction.name = "umap.unintegrated")

ifnb_sub <- RunUMAP(ifnb_sub, reduction = "integrated.cca", dims = 1:10, reduction.name = "umap.cca")
ifnb_sub <- RunUMAP(ifnb_sub, reduction = "integrated.rpca", dims = 1:10, reduction.name = "umap.rpca")
ifnb_sub <- RunUMAP(ifnb_sub, reduction = "harmony", dims = 1:10, reduction.name = "umap.harmony")
```

```{r}
p1 <- DimPlot(
  ifnb_sub,
  reduction = "umap.unintegrated",
  group.by = "cca_clusters",
  split.by = "stim",  
  combine = FALSE, label.size = 2
)

p1
```

```{r}
p2 <- DimPlot(
  ifnb_sub,
  reduction = "umap.rpca",
  group.by = "rpca_clusters",
  split.by = "stim",
  combine = FALSE, label.size = 2
)
p2
```

```{r}
p3 <- DimPlot(
  ifnb_sub,
  reduction = "umap.harmony",
  group.by = "harmony_clusters",
  split.by = "stim",
  combine = FALSE, label.size = 2
)
p3
```

```{r}
p4 <- DimPlot(
  ifnb_sub,
  reduction = "umap.cca",
  group.by = "cca_clusters",
  split.by = "stim",
  combine = FALSE, label.size = 2
)
p4
```

You can manually set the colors for the clusters, like this: First, get a list of all the built in colors that R knows about and use `grep` to remove anything with `gray` or `grey` in the color name.

```{r}
colors <- grDevices::colors()[grep('gr(a|e)y|light', grDevices::colors(), invert = T)]
```

Then pick enough colors from that list so that each `cca_cluster` has its own color

```{r}
cca_cluster_colors <- sample(x = colors, size = ifnb_sub@meta.data$cca_clusters %>% unique() %>% length())
```

Assign names so that each color is associated with a cluster identity:

```{r}
names(cca_cluster_colors) <-ifnb_sub@meta.data$cca_clusters %>% unique() 
cca_cluster_colors
```

We can do the same and use the `Zissou` palette with `hcl.colors` (run `hcl.pals()` to see all options)

```{r}
zissou_colors <- hcl.colors( ifnb_sub@meta.data$cca_clusters %>% unique() %>% length(), "Zissou 1")
names(zissou_colors) <-ifnb_sub@meta.data$cca_clusters %>% unique() 

```

```{r}

DimPlot(
  ifnb_sub,
  reduction = "umap.cca",
  group.by = "cca_clusters",
  split.by = "stim",
  combine = FALSE, label.size = 2,
  cols = cca_cluster_colors
)
```

We can leave the legend off, use the Zissou colors, omit the `split_by` argument and the legend:

```{r}
zissou_plot <- DimPlot(
  ifnb_sub,
  reduction = "umap.cca",
  group.by = "cca_clusters",
  cols = zissou_colors
) + NoLegend()
```

Then we can label the clusters:

```{r}
LabelClusters(plot = zissou_plot , id = "cca_clusters", box = T, repel = T)
```

Once integrative analysis is complete, you can rejoin the layers - which collapses the individual datasets together and recreates the original counts and data layers. You will need to do this before performing any differential expression analysis. However, you can always resplit the layers in case you would like to reperform integrative analysis.

```{r}
ifnb_sub <- JoinLayers(ifnb_sub, assay ='RNA')
```

## Differential expression analysis

The bulk of Seurat’s differential expression features can be accessed through the `FindMarkers()` function. By default, Seurat performs differential expression (DE) testing based on the non-parametric Wilcoxon rank sum test. To test for DE genes between two specific groups of cells, specify the `ident.1` and `ident.2` parameters. Since we normalized using SCTransform, we have to run `PrepSCTFindMarkers()` first. Given a merged object with multiple SCT models, this function uses minimum of the median UMI (calculated using the raw UMI counts) of individual objects to reverse the individual SCT regression model using minimum of median UMI as the sequencing depth covariate. The counts slot of the SCT assay is replaced with recorrected counts and the data slot is replaced with log1p of recorrected counts. Then set the `DefaultAssay` to be the RNA assay.

```{r}
Idents(ifnb_sub) <- "orig.ident"
ifnb_sub <- PrepSCTFindMarkers(ifnb_sub)
DefaultAssay(ifnb_sub) <- "RNA"

stim_vs_ctrl <- FindMarkers(ifnb_sub, ident.1 = "IMMUNE_STIM", ident.2 = "IMMUNE_CTRL")
head(stim_vs_ctrl %>% dplyr::filter(p_val_adj < .05 & avg_log2FC > 1))
```

The results data frame has the following columns :

```         
p_val : p-value (unadjusted)
avg_log2FC : log fold-change of the average expression between the two groups. Positive values indicate that the feature is more highly expressed in the first group.
pct.1 : The percentage of cells where the feature is detected in the first group
pct.2 : The percentage of cells where the feature is detected in the second group
p_val_adj : Adjusted p-value, based on Bonferroni correction using all features in the dataset.
```

If the `ident.2` argument is omitted, `FindMarkers` will test for differentially expressed features between the group specified by `ident.1` and all other cells. Additionally, the parameter `only.pos` can be set to TRUE to only search for positive markers, i.e. features that are more highly expressed in the ident.1 group.

```{r}
stim_vs_all <- FindMarkers(ifnb_sub, ident.1 = "IMMUNE_STIM", only.pos = T)
head(stim_vs_all %>% dplyr::filter(p_val_adj < .05 & avg_log2FC > 1))
```

Since we only have two groups (`IMMUNE_STIM` and `IMMUNE_CTRL`), the results of `stim_v_all` and `stim_vs_ctrl` are comparing the same groups and results are very similar.

We can switch idents to find marker genes for the clusters:

```{r}
Idents(ifnb_sub) <- 'cca_clusters'
```

Use `FindAllMarkers` to compare each cluster to all the other clusters. For the sake of speed, we are selecting only positive genes that are expressed in at least 90% of the cells for a given cluster:

```{r}
cca_markers <- FindAllMarkers(ifnb_sub, min.pct = .90, only.pos=TRUE)
```

Look at the 3 marker genes with the biggest fold change per cluster

```{r}
top_cluster_markers <- 
  cca_markers %>% 
  group_by(cluster) %>%
  dplyr::filter(avg_log2FC > 1) %>% 
  top_n(n = 3, wt = avg_log2FC)
print(top_cluster_markers, n = 37)
```

Make a `FeaturePlot` to look at the expression of one of the cluster markers. It will plot the `data` slot from the default assay. We can switch the default assay to SCT first and specify that we want to use the `data` slot (log1p(counts)(:

```{r}
DefaultAssay(ifnb_sub) <- "SCT"

FeaturePlot(ifnb_sub, features = c("CD74"), reduction = 'umap.cca', order = T, slot = 'data')
```

We can adjust the default colors and use one of the `viridis` palettes:

```{r}
FeaturePlot(ifnb_sub, features = c("CD74"), reduction = 'umap.cca', order = T, slot = 'data') & scale_color_gradientn(colors = turbo(n = 10, direction = 1))

```

We can add the cluster labels:

```{r}
FeaturePlot(ifnb_sub, features = c("CD74"), reduction = 'umap.cca', order = T, slot = 'data', label = TRUE, repel = TRUE) & scale_color_gradientn(colors = turbo(n = 10, direction = 1))

```

We can use `RColorBrewer` palettes instead and specify that we want to drop the colors on the extreme ends of the `Spectral` palette:

```{r}
FeaturePlot(ifnb_sub, features = c("CD74"), reduction = 'umap.cca', order = T, slot = 'data', label = TRUE, repel = TRUE) & scale_color_gradientn(colors = rev(brewer.pal(10, 'Spectral'))[3:8])
```

And add a legend title

```{r}
FeaturePlot(ifnb_sub, features = c("CD74"), reduction = 'umap.cca', order = T, slot = 'data', label = TRUE, repel = TRUE) & scale_color_gradientn(colors = rev(brewer.pal(10, 'Spectral'))[3:8]) & labs(color = "log1p\n(counts)")
```

We can also make a heatmap of the cluster markers:

```{r}
DoHeatmap(subset(ifnb_sub, downsample = 100), features = top_cluster_markers$gene, size = 3)
```

We can customize this heatmap as well:

```{r}
DoHeatmap(subset(ifnb_sub, downsample = 100), features = top_cluster_markers$gene, size = 3) & scale_fill_viridis() 
```

We can adjust which legends are shown, like this:

```{r}
DoHeatmap(subset(ifnb_sub, downsample = 100), features = top_cluster_markers$gene, size = 3) & scale_fill_viridis() & guides(fill=FALSE)
```

Or like this:

```{r}
DoHeatmap(subset(ifnb_sub, downsample = 100), features = top_cluster_markers$gene, size = 3) & scale_fill_viridis() &  guides(colour=FALSE)
```

How long did it take to run through the notebook?

```{r}
nb.end.time <- Sys.time()
nb.end.time - nb.start.time
```
